{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OJ6G_SJVH9rQ"
   },
   "outputs": [],
   "source": [
    "rnd = 42\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "assert transformers.__version__=='2.7.0', 'Please install transformer 2.7.0 (You may need a rust compiler https://rustup.rs/)'\n",
    "import folium\n",
    "assert folium.__version__=='0.2.1'\n",
    "import urllib3\n",
    "assert urllib3.__version__=='1.25.4'\n",
    "import captum\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "dataset = 'IMDB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file_from_google_drive('1hmuG2EFgEQmIA2lCeDZ4pG69KneVIFOS','./data/Text/text_datasets.zip')\n",
    "os.system('unzip ./data/text/text_datasets.zip -d ./data/Text/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23285,
     "status": "ok",
     "timestamp": 1610810423005,
     "user": {
      "displayName": "Francesco BODRIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhWoPtcdMIy7X2yZn1NZbTlnLyFvgDd-Iwx5fLv=s64",
      "userId": "11386110455975912274"
     },
     "user_tz": -60
    },
    "id": "laNBrWCVYLW1",
    "outputId": "f59390f7-ac09-4e30-b47d-a464eb3c18a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB dataset selected\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path):\n",
    "    data = pd.read_csv(path)\n",
    "    X = data['sentence'].values.tolist()\n",
    "    Y = data['label'].values\n",
    "    return X, Y\n",
    "\n",
    "def sst_binary(data_dir='./data/Text/SST/'):\n",
    "    \"\"\"\n",
    "    Stanford Sentiment Treebank.\n",
    "    \"\"\"\n",
    "    trX, trY = load_dataset(os.path.join(data_dir, 'train_binary_sent.csv'))\n",
    "    vaX, vaY = load_dataset(os.path.join(data_dir, 'dev_binary_sent.csv'))\n",
    "    teX, teY = load_dataset(os.path.join(data_dir, 'test_binary_sent.csv'))\n",
    "    return trX+vaX, teX, np.hstack((trY,vaY)), teY\n",
    "\n",
    "def yelp_binary(data_dir='./data/Text/imdb_review_polarity/'):\n",
    "    \"\"\"\n",
    "    Yelp Review Polarity Dataset.\n",
    "    \"\"\"\n",
    "    trX, trY = load_dataset(os.path.join(data_dir, 'train.csv'))\n",
    "    teX, teY = load_dataset(os.path.join(data_dir, 'test.csv'))\n",
    "    return trX, teX, trY, teY\n",
    "\n",
    "def imdb_binary(data_dir='./data/Text/yelp_review_polarity/'):\n",
    "    \"\"\"\n",
    "    Imdb Review Polarity Dataset.\n",
    "    \"\"\"\n",
    "    trX, trY = load_dataset(os.path.join(data_dir, 'train.csv'))\n",
    "    teX, teY = load_dataset(os.path.join(data_dir, 'test.csv'))\n",
    "    return trX, teX, trY, teY\n",
    "\n",
    "if dataset == 'SST':\n",
    "    trX, teX, trY, teY = sst_binary()\n",
    "    print('SST dataset selected')\n",
    "elif dataset == 'IMDB':\n",
    "    trX, teX, trY, teY = imdb_binary()\n",
    "    print('IMDB dataset selected')\n",
    "elif dataset == 'YELP':\n",
    "    trX, teX, trY, teY = yelp_binary()\n",
    "    print('YELP dataset selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qKxEVqZoRKXr"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            with tqdm(unit='B', unit_scale=True, unit_divisor=1024) as bar:\n",
    "                for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                    if chunk:  # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "                        bar.update(CHUNK_SIZE)\n",
    "\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41503,
     "status": "ok",
     "timestamp": 1610810441237,
     "user": {
      "displayName": "Francesco BODRIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhWoPtcdMIy7X2yZn1NZbTlnLyFvgDd-Iwx5fLv=s64",
      "userId": "11386110455975912274"
     },
     "user_tz": -60
    },
    "id": "Ms0ry9-HIsSo",
    "outputId": "36f85f2c-2707-4112-c81d-5b479280749d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "774MB [02:58, 4.54MB/s] \n"
     ]
    }
   ],
   "source": [
    "if dataset == 'SST':\n",
    "    download_file_from_google_drive('1RdM5-KkFuwrfv8luWoCyepBPleiNw3Py','./models/Text/SST_BERT.tgz')\n",
    "    os.system('tar -zxvf ./models/Text/SST_BERT.tgz -C ./models/Text/')\n",
    "elif dataset == 'IMDB':\n",
    "    download_file_from_google_drive('1LwCSzbg6mts9AzuLHikoZou42-ixUuq9','./models/Text/IMDB_BERT.tgz')\n",
    "    os.system('tar -zxvf ./models/Text/IMDB_BERT.tgz -C ./models/Text/')\n",
    "elif dataset == 'YELP':\n",
    "    download_file_from_google_drive('1udzt-GXMKzVmXxUxzYNZ7MjL7z8JcI5P','./models/Text/YELP_BERT.tar.gz')\n",
    "    os.system('tar -zxvf ./models/Text/YELP_BERT.tar.gz -C ./models/Text/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58851,
     "status": "ok",
     "timestamp": 1610810458592,
     "user": {
      "displayName": "Francesco BODRIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhWoPtcdMIy7X2yZn1NZbTlnLyFvgDd-Iwx5fLv=s64",
      "userId": "11386110455975912274"
     },
     "user_tz": -60
    },
    "id": "jYzqHS_C5lAI",
    "outputId": "858b9f59-f2d7-4ef1-e5ad-b3bf6d2605cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francesco/anaconda3/envs/survey/lib/python3.7/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/francesco/anaconda3/envs/survey/lib/python3.7/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/francesco/anaconda3/envs/survey/lib/python3.7/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/francesco/anaconda3/envs/survey/lib/python3.7/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/francesco/anaconda3/envs/survey/lib/python3.7/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/francesco/anaconda3/envs/survey/lib/python3.7/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_TOKENIZER_PATH = './models/Text/'+dataset+'_BERT/BERT_base_uncased_tokenizer.pt'\n",
    "BERT_PATH = './models/Text/'+dataset+'_BERT/BERT_base_uncased.pt'\n",
    "BERT_FT_PATH = './models/Text/'+dataset+'_BERT/'+dataset+'_BERT_FT.pt'\n",
    "\n",
    "BERT_tokenizer = torch.load(BERT_TOKENIZER_PATH)\n",
    "BERT = torch.load(BERT_PATH)\n",
    "\n",
    "class FT_BERT(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, BERT_model, tokenizer):\n",
    "        super(FT_BERT, self).__init__()\n",
    "        self.BERT = BERT_model\n",
    "        self.drop = torch.nn.Dropout(0.1)\n",
    "        self.linear = torch.nn.Linear(768, 2)\n",
    "        self.log_probs = torch.nn.LogSoftmax(dim=-1)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self, input_embeds):\n",
    "        #inputs = self.tokenizer.batch_encode_plus(X, add_special_tokens=True, max_length=256, pad_to_max_length=True)\n",
    "        #input_ids = np.vstack(inputs['input_ids'])\n",
    "        #attention_mask = np.vstack(inputs['attention_mask'])\n",
    "        #token_type_ids = np.vstack(inputs['token_type_ids'])\n",
    "        outputs = self.log_probs(self.linear(self.drop(self.BERT(inputs_embeds=input_embeds)[1])))\n",
    "        return torch.exp(outputs)[:,1]\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.normal_(self.linear.weight, mean=0.0, std=0.02)\n",
    "        torch.nn.init.constant_(self.linear.bias,0)\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "    def __init__(self,trX,trY):\n",
    "        self.trX = trX\n",
    "        self.trY = trY\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trY)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.trX[idx],torch.tensor(self.trY[idx]))\n",
    "\n",
    "train_data = TextDataset(trX, trY)\n",
    "test_data = TextDataset(teX, teY)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "model = FT_BERT(BERT,BERT_tokenizer).to(DEVICE)\n",
    "device = torch.device(DEVICE)\n",
    "model.load_state_dict(torch.load(BERT_FT_PATH,map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDUOfMQPxv5M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMlu877xobz0"
   },
   "source": [
    "# Saliency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GnNJhcBPiz7x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('mkdir ./models/Text/BERT_no_attention')\n",
    "BERT.save_pretrained('./models/Text/BERT_no_attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58227,
     "status": "ok",
     "timestamp": 1610810464242,
     "user": {
      "displayName": "Francesco BODRIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhWoPtcdMIy7X2yZn1NZbTlnLyFvgDd-Iwx5fLv=s64",
      "userId": "11386110455975912274"
     },
     "user_tz": -60
    },
    "id": "zMkcyDEMjbFr",
    "outputId": "cd483b00-0b9f-49b9-af1e-4367194f5415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig(output_attentions=True)\n",
    "# Initializing a model from the bert-base-uncased style configuration\n",
    "BERT = BertModel(configuration).to(DEVICE)\n",
    "BERT.from_pretrained('./models/Text/BERT_no_attention/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1610810762383,
     "user": {
      "displayName": "Francesco BODRIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhWoPtcdMIy7X2yZn1NZbTlnLyFvgDd-Iwx5fLv=s64",
      "userId": "11386110455975912274"
     },
     "user_tz": -60
    },
    "id": "QWaNj4uEyHnS",
    "outputId": "daaeedc1-d732-48f1-ca84-b9951cd2e84f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence='read the book, forget the movie!'\n",
    "\n",
    "with torch.no_grad():\n",
    "    d = BERT_tokenizer.batch_encode_plus([sentence],add_special_tokens=True,pad_to_max_length=True)\n",
    "    input_embedding = model.BERT.embeddings(torch.tensor(d['input_ids']).to(DEVICE))\n",
    "    output = BERT.forward(inputs_embeds=input_embedding)\n",
    "\n",
    "attention = np.sum(output[2][0][0,:,1:-1,1:-1].detach().cpu().numpy(),axis=0)\n",
    "\n",
    "import seaborn as sb\n",
    "sb.set_theme()\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(15, 5))\n",
    "sb.heatmap(attention, annot=False, linewidths=1, ax=ax,cmap='YlOrRd')\n",
    "plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "ax.set_xticklabels(BERT_tokenizer.tokenize(sentence),fontsize=24)\n",
    "ax.set_yticklabels(BERT_tokenizer.tokenize(sentence),fontsize=24,va='center',rotation='horizontal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Highlighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1605015102219,
     "user": {
      "displayName": "Francesco BODRIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhWoPtcdMIy7X2yZn1NZbTlnLyFvgDd-Iwx5fLv=s64",
      "userId": "11386110455975912274"
     },
     "user_tz": -60
    },
    "id": "V1Pi6qNEfTIw",
    "outputId": "5aa02dee-1530-4d2d-ae6e-2d5a5cb4969c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The movie is not that bad, Ringo Lam sucks. I hate when Van Damme has love in his movies, van Damme is good only when he doesn't have love in his movies.\""
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teX[5317]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZGoIdvCcKD7"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "bwr = cm.get_cmap('bwr', 256)\n",
    "\n",
    "def rescale_score_by_abs (score, max_score, min_score):\n",
    "    \"\"\"\n",
    "    rescale positive score to the range [0.5, 1.0], negative score to the range [0.0, 0.5],\n",
    "    using the extremal scores max_score and min_score for normalization\n",
    "    \"\"\"\n",
    "    \n",
    "    # CASE 1: positive AND negative scores occur --------------------\n",
    "    if max_score>0 and min_score<0:\n",
    "    \n",
    "        if max_score >= abs(min_score):   # deepest color is positive\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/max_score)\n",
    "            else:\n",
    "                return 0.5 - 0.5*(abs(score)/max_score)\n",
    "\n",
    "        else:                             # deepest color is negative\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/abs(min_score))\n",
    "            else:\n",
    "                return 0.5 - 0.5*(score/min_score)   \n",
    "    \n",
    "    # CASE 2: ONLY positive scores occur -----------------------------       \n",
    "    elif max_score>0 and min_score>=0: \n",
    "        if max_score == min_score:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.5 + 0.5*(score/max_score)\n",
    "    \n",
    "    # CASE 3: ONLY negative scores occur -----------------------------\n",
    "    elif max_score<=0 and min_score<0: \n",
    "        if max_score == min_score:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 0.5 - 0.5*(score/min_score)    \n",
    "  \n",
    "      \n",
    "def getRGB (c_tuple):\n",
    "    return \"#%02x%02x%02x\"%(int(c_tuple[0]*255), int(c_tuple[1]*255), int(c_tuple[2]*255))\n",
    "\n",
    "     \n",
    "def span_word (word, score, colormap):\n",
    "    return \"<span style=\\\"background-color:\"+getRGB(colormap(score))+\"\\\">\"+word+\"</span>\"\n",
    "\n",
    "def html_heatmap (words, scores, cmap_name=\"bwr\"):\n",
    "    \n",
    "    colormap  = bwr# plt.get_cmap(cmap_name)\n",
    "     \n",
    "    assert len(words)==len(scores)\n",
    "    max_s     = max(scores)\n",
    "    min_s     = min(scores)\n",
    "    \n",
    "    output_text = \"\"\n",
    "    \n",
    "    for idx, w in enumerate(words):\n",
    "        score       = rescale_score_by_abs(scores[idx], max_s, min_s)\n",
    "        output_text = output_text + span_word(w, score, colormap) + \" \"\n",
    "    \n",
    "    return output_text + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRZd7KxQLdqn"
   },
   "source": [
    "# IntGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Viwsf3iN6kX6"
   },
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients, visualization, TokenReferenceBase\n",
    "\n",
    "ig = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZvVTmVY7STG",
    "outputId": "5db4bbc1-2c8b-4cb5-c6a3-83578548800a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5227432250976562\n"
     ]
    }
   ],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1):\n",
    "\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "\n",
    "    input_ids = [BERT_tokenizer.encode(sentence, add_special_tokens = True, max_length=256)]\n",
    "    input_embedding = model_wrapper.BERT.embeddings(torch.tensor(input_ids).to(DEVICE))\n",
    "\n",
    "    baseline = np.array(input_ids).copy()\n",
    "    baseline[0, 1:-1] = 0\n",
    "    baseline_embedding = model_wrapper.BERT.embeddings(torch.tensor(baseline).to(DEVICE))\n",
    "\n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    attributions_ig, delta = ig.attribute(input_embedding, baseline_embedding, n_steps=250, return_convergence_delta=True, internal_batch_size=128)\n",
    "\n",
    "    return attributions_ig\n",
    "    \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "att_igs = []\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "\n",
    "for i in range(5317,5318):#tqdm(range(len(teX))):\n",
    "    att_igs.append(interpret_sentence(model, teX[i]).sum(dim=-1).squeeze(0).to('cpu').detach().numpy()[1:-1])\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "_VeKpwz1RiRY",
    "outputId": "02dd8e80-ed45-4547-e264-c9d761bb185e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> <span style=\"background-color:#fff0f0\">the</span> <span style=\"background-color:#ffe6e6\">movie</span> <span style=\"background-color:#ffd0d0\">is</span> <span style=\"background-color:#ceceff\">not</span> <span style=\"background-color:#ff8282\">that</span> <span style=\"background-color:#d2d2ff\">bad</span> <span style=\"background-color:#ffc3c3\">,</span> <span style=\"background-color:#f3f3ff\">ringo</span> <span style=\"background-color:#fefeff\">lam</span> <span style=\"background-color:#0000ff\">sucks</span> <span style=\"background-color:#fff8f8\">.</span> <span style=\"background-color:#eaeaff\">i</span> <span style=\"background-color:#e3e3ff\">hate</span> <span style=\"background-color:#ffd8d8\">when</span> <span style=\"background-color:#fff6f6\">van</span> <span style=\"background-color:#ffecec\">dam</span> <span style=\"background-color:#f2f2ff\">##me</span> <span style=\"background-color:#d0d0ff\">has</span> <span style=\"background-color:#ffd8d8\">love</span> <span style=\"background-color:#ececff\">in</span> <span style=\"background-color:#fffefe\">his</span> <span style=\"background-color:#fffcfc\">movies</span> <span style=\"background-color:#fffefe\">,</span> <span style=\"background-color:#fffcfc\">van</span> <span style=\"background-color:#d8d8ff\">dam</span> <span style=\"background-color:#fefeff\">##me</span> <span style=\"background-color:#ffeeee\">is</span> <span style=\"background-color:#eaeaff\">good</span> <span style=\"background-color:#ffecec\">only</span> <span style=\"background-color:#fffafa\">when</span> <span style=\"background-color:#f6f6ff\">he</span> <span style=\"background-color:#dadaff\">doesn</span> <span style=\"background-color:#fafaff\">'</span> <span style=\"background-color:#e6e6ff\">t</span> <span style=\"background-color:#c8c8ff\">have</span> <span style=\"background-color:#ffe2e2\">love</span> <span style=\"background-color:#fff8f8\">in</span> <span style=\"background-color:#dedeff\">his</span> <span style=\"background-color:#fff8f8\">movies</span> <span style=\"background-color:#e2e2ff\">.</span> \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5317\n",
    "tokens = BERT_tokenizer.tokenize(teX[idx])\n",
    "scores = att_igs[0]\n",
    "display(HTML('<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> '+html_heatmap(tokens,scores)+'</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D86J-4viv0MK"
   },
   "source": [
    "# DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YDKnz3NRKSP"
   },
   "outputs": [],
   "source": [
    "from captum.attr import DeepLift, visualization, TokenReferenceBase\n",
    "\n",
    "explainer = DeepLift(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "2a3784cb69e4405abac06bf7b5739eb6",
      "1a3029f7af5548ec856f8841ff14c148",
      "8fdade6461aa4fb4a920018e9d44260a",
      "b5c8a1dcdd50426aa99d4a577e096038",
      "23f040328d5c4a10a2c9ff2265dc3b5d",
      "9ec40da5ecda488ea2ee906d17e358d0",
      "69070b5509b341b19e79a5a0b75d276a",
      "f3a352394c75411291f04c81853a203e"
     ]
    },
    "id": "GltAPgXERR_A",
    "outputId": "bd60aa3d-a75e-4c48-9246-d0231b3844ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3784cb69e4405abac06bf7b5739eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/captum/_utils/gradient.py:58: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  if input.grad is not None:\n",
      "/usr/local/lib/python3.7/dist-packages/captum/attr/_core/deep_lift.py:325: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  after the attribution is finished\"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/captum/_utils/gradient.py:87: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  if input.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.2710409164428711\n"
     ]
    }
   ],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1):\n",
    "\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "\n",
    "    input_ids = [BERT_tokenizer.encode(sentence, add_special_tokens = True, max_length=256)]\n",
    "    input_embedding = model_wrapper.BERT.embeddings(torch.tensor(input_ids).to(DEVICE))\n",
    "\n",
    "    baseline = np.array(input_ids).copy()\n",
    "    baseline[0, 1:-1] = 0\n",
    "    baseline_embedding = model_wrapper.BERT.embeddings(torch.tensor(baseline).to(DEVICE))\n",
    "\n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    attributions_ig, delta = explainer.attribute(input_embedding, baseline_embedding, return_convergence_delta=True)\n",
    "\n",
    "    return attributions_ig\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle \n",
    "\n",
    "att = []\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "\n",
    "for i in tqdm(range(5317,5318)):\n",
    "    att.append(interpret_sentence(model, teX[i]).sum(dim=-1).squeeze(0).to('cpu').detach().numpy()[1:-1])\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "rJA6simcRrsJ",
    "outputId": "6e9dbee5-46a1-4efb-b545-4996a547ad4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> <span style=\"background-color:#ffa0a0\">the</span> <span style=\"background-color:#d8d8ff\">movie</span> <span style=\"background-color:#ffd8d8\">is</span> <span style=\"background-color:#ffbebe\">not</span> <span style=\"background-color:#ff9696\">that</span> <span style=\"background-color:#9c9cff\">bad</span> <span style=\"background-color:#ff0000\">,</span> <span style=\"background-color:#6666ff\">ringo</span> <span style=\"background-color:#2e2eff\">lam</span> <span style=\"background-color:#ff6464\">sucks</span> <span style=\"background-color:#d8d8ff\">.</span> <span style=\"background-color:#f2f2ff\">i</span> <span style=\"background-color:#ffb2b2\">hate</span> <span style=\"background-color:#ffdede\">when</span> <span style=\"background-color:#e6e6ff\">van</span> <span style=\"background-color:#f6f6ff\">dam</span> <span style=\"background-color:#ffe8e8\">##me</span> <span style=\"background-color:#ffdede\">has</span> <span style=\"background-color:#fffcfc\">love</span> <span style=\"background-color:#fff6f6\">in</span> <span style=\"background-color:#ffecec\">his</span> <span style=\"background-color:#fcfcff\">movies</span> <span style=\"background-color:#fff4f4\">,</span> <span style=\"background-color:#ffecec\">van</span> <span style=\"background-color:#fffefe\">dam</span> <span style=\"background-color:#f6f6ff\">##me</span> <span style=\"background-color:#ffdcdc\">is</span> <span style=\"background-color:#ffe6e6\">good</span> <span style=\"background-color:#dcdcff\">only</span> <span style=\"background-color:#e2e2ff\">when</span> <span style=\"background-color:#f2f2ff\">he</span> <span style=\"background-color:#fcfcff\">doesn</span> <span style=\"background-color:#fcfcff\">'</span> <span style=\"background-color:#e0e0ff\">t</span> <span style=\"background-color:#fafaff\">have</span> <span style=\"background-color:#fffafa\">love</span> <span style=\"background-color:#fcfcff\">in</span> <span style=\"background-color:#f0f0ff\">his</span> <span style=\"background-color:#f0f0ff\">movies</span> <span style=\"background-color:#ffd0d0\">.</span> \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5317\n",
    "tokens = BERT_tokenizer.tokenize(teX[idx])\n",
    "scores = att[0]\n",
    "display(HTML('<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> '+html_heatmap(tokens,scores)+'</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wn2X6lSzWDgh"
   },
   "source": [
    "# Gradient x Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9NRNBrURSEH"
   },
   "outputs": [],
   "source": [
    "from captum.attr import InputXGradient, visualization, TokenReferenceBase\n",
    "\n",
    "explainer = InputXGradient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "65c9326896a346ea98b4852bbf72fbfa",
      "5eab5d972532454ca25a622ca563717b",
      "7e2bb5aef8c74359a151de4294b493b6",
      "ec64275385194a3eaa24d0bad0e9a1e0",
      "a7369cd195ee40ba882936ecaaa94bf3",
      "45ed0720cdff4247b09300fc4b507873",
      "f3673ae466f74dbe8e85f4437f76d7f0",
      "b72c705875a2436eac570caef1266d2e"
     ]
    },
    "id": "RptTmHWcWIGr",
    "outputId": "3e27cd9d-8ab9-46ad-89ad-2d463a5f25e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c9326896a346ea98b4852bbf72fbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.15769386291503906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/captum/_utils/gradient.py:58: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  if input.grad is not None:\n",
      "/usr/local/lib/python3.7/dist-packages/captum/_utils/gradient.py:87: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  if input.grad is not None:\n"
     ]
    }
   ],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1):\n",
    "\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "\n",
    "    input_ids = [BERT_tokenizer.encode(sentence, add_special_tokens = True, max_length=256)]\n",
    "    input_embedding = model_wrapper.BERT.embeddings(torch.tensor(input_ids).to(DEVICE))\n",
    "\n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    attributions_ig = explainer.attribute(input_embedding)\n",
    "\n",
    "    return attributions_ig\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "att = []\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "import pickle\n",
    "\n",
    "for i in tqdm(range(5317,5318)):\n",
    "    att.append(interpret_sentence(model, teX[i]).sum(dim=-1).squeeze(0).to('cpu').detach().numpy()[1:-1])\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "WHpjEKMqSI9r",
    "outputId": "180b574c-9ad5-435e-a4ba-7fd041f5fd6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> <span style=\"background-color:#ff7c7c\">the</span> <span style=\"background-color:#e6e6ff\">movie</span> <span style=\"background-color:#ffc2c2\">is</span> <span style=\"background-color:#ffbaba\">not</span> <span style=\"background-color:#ff8a8a\">that</span> <span style=\"background-color:#9c9cff\">bad</span> <span style=\"background-color:#ff6e6e\">,</span> <span style=\"background-color:#9696ff\">ringo</span> <span style=\"background-color:#0000ff\">lam</span> <span style=\"background-color:#ff4c4c\">sucks</span> <span style=\"background-color:#ffeaea\">.</span> <span style=\"background-color:#e6e6ff\">i</span> <span style=\"background-color:#ffb2b2\">hate</span> <span style=\"background-color:#ffdcdc\">when</span> <span style=\"background-color:#eaeaff\">van</span> <span style=\"background-color:#e0e0ff\">dam</span> <span style=\"background-color:#fff0f0\">##me</span> <span style=\"background-color:#ffe4e4\">has</span> <span style=\"background-color:#fff6f6\">love</span> <span style=\"background-color:#fefeff\">in</span> <span style=\"background-color:#ffe8e8\">his</span> <span style=\"background-color:#fcfcff\">movies</span> <span style=\"background-color:#fff0f0\">,</span> <span style=\"background-color:#ffe4e4\">van</span> <span style=\"background-color:#fafaff\">dam</span> <span style=\"background-color:#f2f2ff\">##me</span> <span style=\"background-color:#ffd6d6\">is</span> <span style=\"background-color:#ffe8e8\">good</span> <span style=\"background-color:#d3d3ff\">only</span> <span style=\"background-color:#e0e0ff\">when</span> <span style=\"background-color:#e8e8ff\">he</span> <span style=\"background-color:#fafaff\">doesn</span> <span style=\"background-color:#f3f3ff\">'</span> <span style=\"background-color:#d2d2ff\">t</span> <span style=\"background-color:#f8f8ff\">have</span> <span style=\"background-color:#fffafa\">love</span> <span style=\"background-color:#f3f3ff\">in</span> <span style=\"background-color:#f0f0ff\">his</span> <span style=\"background-color:#f3f3ff\">movies</span> <span style=\"background-color:#ffe4e4\">.</span> \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5317\n",
    "tokens = BERT_tokenizer.tokenize(teX[idx])\n",
    "scores = att[0]\n",
    "display(HTML('<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> '+html_heatmap(tokens,scores)+'</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ES1Iiu2xWC3Z",
    "outputId": "2ff8065b-0b57-48c4-ef8c-2718e4c94b54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "BERT_TOKENIZER_PATH = './'+dataset+'_BERT/BERT_base_uncased_tokenizer.pt'\n",
    "BERT_PATH = './'+dataset+'_BERT/BERT_base_uncased.pt'\n",
    "BERT_FT_PATH = './'+dataset+'_BERT/'+dataset+'_BERT_FT.pt'\n",
    "\n",
    "BERT_tokenizer = torch.load(BERT_TOKENIZER_PATH)\n",
    "BERT = torch.load(BERT_PATH)\n",
    "\n",
    "class FT_BERT(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, BERT_model, tokenizer):\n",
    "        super(FT_BERT, self).__init__()\n",
    "        self.BERT = BERT_model\n",
    "        self.drop = torch.nn.Dropout(0.1)\n",
    "        self.linear = torch.nn.Linear(768, 2)\n",
    "        self.log_probs = torch.nn.LogSoftmax(dim=-1)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self, X):\n",
    "        if type(X)!=list:\n",
    "            X = [X]\n",
    "        inputs = self.tokenizer.batch_encode_plus(X, add_special_tokens=True, max_length=256, pad_to_max_length=True)\n",
    "        input_ids = np.vstack(inputs['input_ids'])\n",
    "        attention_mask = np.vstack(inputs['attention_mask'])\n",
    "        token_type_ids = np.vstack(inputs['token_type_ids'])\n",
    "        return self.log_probs(self.linear(self.drop(self.BERT(torch.tensor(input_ids).to(DEVICE),\n",
    "                                                              torch.tensor(attention_mask).to(DEVICE),\n",
    "                                                              torch.tensor(token_type_ids).to(DEVICE))[1])))\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.normal_(self.linear.weight, mean=0.0, std=0.02)\n",
    "        torch.nn.init.constant_(self.linear.bias,0)\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "    def __init__(self,trX,trY):\n",
    "        self.trX = trX\n",
    "        self.trY = trY\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trY)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.trX[idx],torch.tensor(self.trY[idx]))\n",
    "\n",
    "train_data = TextDataset(trX, trY)\n",
    "test_data = TextDataset(teX, teY)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "model = FT_BERT(BERT,BERT_tokenizer).to(DEVICE)\n",
    "device = torch.device(DEVICE)\n",
    "model.load_state_dict(torch.load(BERT_FT_PATH,map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3RButnFTeBn",
    "outputId": "116d7dae-a6e3-4ad7-9d16-700465cee300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.738651275634766\n"
     ]
    }
   ],
   "source": [
    "class PredDataset(data.Dataset):\n",
    "    def __init__(self,trX):\n",
    "        self.trX = trX\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trX)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.trX[idx])\n",
    "\n",
    "def get_sentiment(input):\n",
    "    test_data = PredDataset(input)\n",
    "    test_data_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "    \n",
    "    y_pred = []\n",
    "    for Xb in test_data_loader:   \n",
    "        model.eval()\n",
    "        y_pred.append(model(Xb).to('cpu').detach().numpy())\n",
    "        \n",
    "    return np.exp(np.vstack(y_pred))\n",
    "\n",
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class_names = [\"Negative\", \"Positive\"]\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names,split_expression='\\s',bow=False,mask_string='')\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "lime_score=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(5317,5318):#len(teX)):\n",
    "        exp = explainer.explain_instance(' '.join(BERT_tokenizer.tokenize(teX[i])), get_sentiment, num_features=256, num_samples=1500)\n",
    "\n",
    "        lime_score.append(np.hstack((np.array(exp.as_list())[:,0].reshape(-1,1), np.array(exp.as_map()[1]))).tolist())\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "dGTKCim9chWV",
    "outputId": "192bc651-f69c-4b69-fd43-6cc4161093d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> <span style=\"background-color:#fffafa\">the</span> <span style=\"background-color:#e0e0ff\">movie</span> <span style=\"background-color:#ffdada\">is</span> <span style=\"background-color:#ff4141\">not</span> <span style=\"background-color:#fefeff\">that</span> <span style=\"background-color:#d3d3ff\">bad</span> <span style=\"background-color:#a6a6ff\">,</span> <span style=\"background-color:#fff6f6\">ringo</span> <span style=\"background-color:#e8e8ff\">lam</span> <span style=\"background-color:#0000ff\">sucks</span> <span style=\"background-color:#b3b3ff\">.</span> <span style=\"background-color:#f6f6ff\">i</span> <span style=\"background-color:#9a9aff\">hate</span> <span style=\"background-color:#f3f3ff\">when</span> <span style=\"background-color:#f8f8ff\">van</span> <span style=\"background-color:#f8f8ff\">dam</span> <span style=\"background-color:#fff4f4\">##me</span> <span style=\"background-color:#fffcfc\">has</span> <span style=\"background-color:#ffdcdc\">love</span> <span style=\"background-color:#f0f0ff\">in</span> <span style=\"background-color:#fafaff\">his</span> <span style=\"background-color:#fffefe\">movies</span> <span style=\"background-color:#fff8f8\">,</span> <span style=\"background-color:#f8f8ff\">van</span> <span style=\"background-color:#f3f3ff\">dam</span> <span style=\"background-color:#fff2f2\">##me</span> <span style=\"background-color:#f6f6ff\">is</span> <span style=\"background-color:#ffdede\">good</span> <span style=\"background-color:#ffdede\">only</span> <span style=\"background-color:#ffe8e8\">when</span> <span style=\"background-color:#fffafa\">he</span> <span style=\"background-color:#fefeff\">doesn</span> <span style=\"background-color:#ececff\">'</span> <span style=\"background-color:#e8e8ff\">t</span> <span style=\"background-color:#fffcfc\">have</span> <span style=\"background-color:#fefeff\">love</span> <span style=\"background-color:#fff6f6\">in</span> <span style=\"background-color:#fffcfc\">his</span> <span style=\"background-color:#e6e6ff\">movies</span> <span style=\"background-color:#f6f6ff\">.</span> \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5317\n",
    "tokens = BERT_tokenizer.tokenize(teX[idx])\n",
    "scores = np.stack(lime_score[0])\n",
    "scores = scores[np.argsort(scores[:,1].astype(float).astype(int)),:][:,2].astype(float)\n",
    "display(HTML('<div style=\"background-color:#ffffff; height:120px; font-size:36pt; color:#424242; text-align:left;\"> '+html_heatmap(tokens,scores)+'</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNG17VGQcXonySt7xBwlp3q",
   "collapsed_sections": [
    "rMlu877xobz0",
    "uRZd7KxQLdqn",
    "D86J-4viv0MK",
    "wn2X6lSzWDgh",
    "iocoNysWeoxj"
   ],
   "mount_file_id": "1EDMni6SJSjQKm0q3tMGxFlZ-YlCGBOWu",
   "name": "XAI_survey_text.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01bd6896b63d477fbbceb7eed5e3a213": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7a64a5fef2d45e18cae20ebbda016ad",
      "placeholder": "",
      "style": "IPY_MODEL_60d98c7af05d40cdac54d23f08524f4a",
      "value": " 100/100 [00:15&lt;00:00,  6.37it/s]"
     }
    },
    "05be29f885c14c138f6aa41bfc13f8ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0991b2b8c947436f9a13dd684091e50f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e95b6bb7ac0482488e6007d191816c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "60d98c7af05d40cdac54d23f08524f4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "750df9fb796046e696c318e2d93e2f5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0991b2b8c947436f9a13dd684091e50f",
      "placeholder": "",
      "style": "IPY_MODEL_cca6d971ac644eb2b291e69852050b5b",
      "value": " 100/100 [00:07&lt;00:00, 13.87it/s]"
     }
    },
    "9cf0937155574cb9aa769d0fad0619d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9d178dbca9140c285ae147c8297fc98",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e95b6bb7ac0482488e6007d191816c2",
      "value": 100
     }
    },
    "9d9ab0332a5349dda6d2003f098e2b1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc1526af30f14aafb6c9359b104251f8",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a857cb1bfb2f4051a58361ffb0e65046",
      "value": 100
     }
    },
    "a46750fca1a54e42a8da4e5475dea61d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d9ab0332a5349dda6d2003f098e2b1d",
       "IPY_MODEL_01bd6896b63d477fbbceb7eed5e3a213"
      ],
      "layout": "IPY_MODEL_afb584cbaa2249b7b2aa7b9e646193f0"
     }
    },
    "a857cb1bfb2f4051a58361ffb0e65046": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "afb584cbaa2249b7b2aa7b9e646193f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc1526af30f14aafb6c9359b104251f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9d178dbca9140c285ae147c8297fc98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cca6d971ac644eb2b291e69852050b5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7a64a5fef2d45e18cae20ebbda016ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f782d55fb04b4e28afeac7c868d6d28c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9cf0937155574cb9aa769d0fad0619d4",
       "IPY_MODEL_750df9fb796046e696c318e2d93e2f5e"
      ],
      "layout": "IPY_MODEL_05be29f885c14c138f6aa41bfc13f8ae"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
